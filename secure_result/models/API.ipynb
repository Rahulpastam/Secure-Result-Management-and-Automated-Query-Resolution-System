{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a302771d8ebc4bc8a7b4732395c55a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0eb562796c354205b0a7ff2d433fef3e",
              "IPY_MODEL_24c81f2524ed4e2c9346fe10a361afbf",
              "IPY_MODEL_ad418a252407493ca3a0b9286a0913e4"
            ],
            "layout": "IPY_MODEL_b3549b3fc10849e08b531f8d64a19565"
          }
        },
        "0eb562796c354205b0a7ff2d433fef3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31824e8d0022403e94d1ce3409fcc90d",
            "placeholder": "​",
            "style": "IPY_MODEL_bebb2c1e89d348e29344df766b5da1ff",
            "value": "Batches: 100%"
          }
        },
        "24c81f2524ed4e2c9346fe10a361afbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6dd824b971f4cc49b47db3cd8be6850",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72b0dd19468b4bb6a5abf1ace697d327",
            "value": 16
          }
        },
        "ad418a252407493ca3a0b9286a0913e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4e96031e76c41c58b7229ad37b4bf43",
            "placeholder": "​",
            "style": "IPY_MODEL_49db10a8d26c400b87410372a34455e0",
            "value": " 16/16 [00:03&lt;00:00,  4.79it/s]"
          }
        },
        "b3549b3fc10849e08b531f8d64a19565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31824e8d0022403e94d1ce3409fcc90d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bebb2c1e89d348e29344df766b5da1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6dd824b971f4cc49b47db3cd8be6850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b0dd19468b4bb6a5abf1ace697d327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4e96031e76c41c58b7229ad37b4bf43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49db10a8d26c400b87410372a34455e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_Te0Fo3IOdz8"
      },
      "outputs": [],
      "source": [
        "# Colab cell 1\n",
        "!pip install -q fastapi uvicorn[standard] pyngrok joblib sentence-transformers lifelines scikit-learn flask nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 2\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfg1RKMUO6r1",
        "outputId": "87c68039-e8af-4e8d-ff85-07941162307b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import os\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Optional\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "Ish0fELFPAw4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# webserver libs\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "UbUnoTN_PCkl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP/ML libs\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# import lifelines (for survival model)\n",
        "from lifelines import CoxPHFitter"
      ],
      "metadata": {
        "id": "GFoWQ42rPESX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "s4M0E5hXPFwo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text cleaning helper (use your existing cleaning logic)\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "STOP = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSu9lI3KPH2n",
        "outputId": "4c2f8a7f-5cb0-44de-d955-497cd829bb01"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    t = re.sub(r'[^a-zA-Z0-9\\s]', ' ', str(text))\n",
        "    t = t.lower()\n",
        "    t = \" \".join([w for w in t.split() if w not in STOP])\n",
        "    return t.strip()"
      ],
      "metadata": {
        "id": "Jwm9XIt7OxQz"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 3\n",
        "DRIVE_BASE = Path(\"/content/drive/MyDrive/Secure-Result\")  # adjust\n",
        "MODEL_DIR = DRIVE_BASE / \"models\"          # where you dumped models\n",
        "DATA_DIR = DRIVE_BASE / \"Datasets\"                         # complaints.csv and resolved_complaints.csv\n",
        "\n",
        "print(\"MODEL_DIR:\", MODEL_DIR)\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4KWu8YCPLXT",
        "outputId": "a338aef3-ce05-44e2-d094-6d114f2ab27a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL_DIR: /content/drive/MyDrive/Secure-Result/models\n",
            "DATA_DIR: /content/drive/MyDrive/Secure-Result/Datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 4\n",
        "# Load classifier + vectorizer\n",
        "classifier_path = MODEL_DIR / \"complaint_type_classifier.pkl\"\n",
        "vectorizer_path = MODEL_DIR / \"tfidf_vectorizer.pkl\""
      ],
      "metadata": {
        "id": "GD0x9tUcPWU_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = joblib.load(classifier_path)\n",
        "vectorizer = joblib.load(vectorizer_path)"
      ],
      "metadata": {
        "id": "RSrdCkWqPXw5"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load resolved cases csv (for SBERT similarity)\n",
        "resolved_csv = DATA_DIR / \"resolved_complaints_dataset.csv\"\n",
        "resolved_df = pd.read_csv(resolved_csv)\n",
        "resolved_df[\"Cleaned Complaint Text\"] = resolved_df[\"Complaint Text\"].astype(str).apply(clean_text)"
      ],
      "metadata": {
        "id": "Eb9O8wL_PZIF"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SBERT and precompute embeddings\n",
        "sbert_model_name = \"all-MiniLM-L6-v2\"\n",
        "sbert = SentenceTransformer(sbert_model_name)\n",
        "resolved_embeddings = sbert.encode(resolved_df[\"Cleaned Complaint Text\"].tolist(), show_progress_bar=True, convert_to_numpy=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a302771d8ebc4bc8a7b4732395c55a22",
            "0eb562796c354205b0a7ff2d433fef3e",
            "24c81f2524ed4e2c9346fe10a361afbf",
            "ad418a252407493ca3a0b9286a0913e4",
            "b3549b3fc10849e08b531f8d64a19565",
            "31824e8d0022403e94d1ce3409fcc90d",
            "bebb2c1e89d348e29344df766b5da1ff",
            "f6dd824b971f4cc49b47db3cd8be6850",
            "72b0dd19468b4bb6a5abf1ace697d327",
            "c4e96031e76c41c58b7229ad37b4bf43",
            "49db10a8d26c400b87410372a34455e0"
          ]
        },
        "id": "v2-Twl8BPa1p",
        "outputId": "cb7e8b37-9142-4181-be38-f41f4ffe0e87"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a302771d8ebc4bc8a7b4732395c55a22"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SLA survival model (lifelines CoxPH fitted and saved)\n",
        "sla_model_path = MODEL_DIR / \"sla_survival_model.pkl\"\n",
        "cph = None\n",
        "if sla_model_path.exists():\n",
        "    cph = joblib.load(sla_model_path)\n",
        "else:\n",
        "    print(\"SLA model not found at\", sla_model_path)"
      ],
      "metadata": {
        "id": "r0pIEbZZPfDl"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load anomaly model (optional)\n",
        "anomaly_path = MODEL_DIR / \"anomaly_model.pkl\"\n",
        "anomaly_model = None\n",
        "if anomaly_path.exists():\n",
        "    anomaly_model = joblib.load(anomaly_path)"
      ],
      "metadata": {
        "id": "woG6xjPxPhCr"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you used label encoders etc, load them too\n",
        "le_student_program_path = MODEL_DIR / \"le_student_program.pkl\"\n",
        "le_faculty_department_path = MODEL_DIR / \"le_faculty_department.pkl\"\n",
        "le_student_program = joblib.load(le_student_program_path) if le_student_program_path.exists() else None\n",
        "le_faculty_department = joblib.load(le_faculty_department_path) if le_faculty_department_path.exists() else None\n",
        "\n",
        "print(\"Loaded: classifier, vectorizer, sbert (and embeddings), SLA model:\", bool(cph), \"anomaly:\", bool(anomaly_model))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5UcHmjOPUkY",
        "outputId": "f918b8dc-f1fa-459b-fd32-bd8314710c6f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: classifier, vectorizer, sbert (and embeddings), SLA model: True anomaly: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 5\n",
        "def predict_category(text):\n",
        "    cleaned = clean_text(text)\n",
        "    X = vectorizer.transform([cleaned])\n",
        "    result = {}\n",
        "    # classification + confidence\n",
        "    if hasattr(classifier, \"predict_proba\"):\n",
        "        probs = classifier.predict_proba(X)[0]\n",
        "        idx = int(np.argmax(probs))\n",
        "        pred = classifier.classes_[idx]\n",
        "        conf = float(probs[idx])\n",
        "    else:\n",
        "        pred = classifier.predict(X)[0]\n",
        "        conf = 0.8\n",
        "    # top keywords if linear model\n",
        "    top_keywords = []\n",
        "    try:\n",
        "        if hasattr(classifier, \"coef_\"):\n",
        "            class_index = list(classifier.classes_).index(pred)\n",
        "            coefs = classifier.coef_[class_index]\n",
        "            topn = np.argsort(coefs)[-5:][::-1]\n",
        "            feature_names = vectorizer.get_feature_names_out()\n",
        "            top_keywords = [feature_names[i] for i in topn]\n",
        "    except Exception:\n",
        "        top_keywords = []\n",
        "    return {\"prediction\": str(pred), \"confidence\": conf, \"top_keywords\": top_keywords}"
      ],
      "metadata": {
        "id": "d0m-bOyFPpMh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similar_complaint(text, top_k=1):\n",
        "    cleaned = clean_text(text)\n",
        "    emb = sbert.encode([cleaned], convert_to_numpy=True)\n",
        "    sims = cosine_similarity(emb, resolved_embeddings)[0]\n",
        "    top_idx = np.argsort(sims)[-top_k:][::-1]\n",
        "    resp = []\n",
        "    for idx in top_idx:\n",
        "        row = resolved_df.iloc[int(idx)]\n",
        "        resp.append({\n",
        "            \"index\": int(idx),\n",
        "            \"score\": float(sims[int(idx)]),\n",
        "            \"complaint_type\": row.get(\"Complaint Type\", \"\"),\n",
        "            \"complaint_text\": row.get(\"Complaint Text\", \"\"),\n",
        "            \"resolution_desc\": row.get(\"Resolution Description\", \"\"),\n",
        "            \"resolution_time\": row.get(\"Resolution Time\", None)\n",
        "        })\n",
        "    return resp"
      ],
      "metadata": {
        "id": "Z6fB-rx5PrNl"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sla_risk(metadata: dict) -> dict:\n",
        "    \"\"\"\n",
        "    metadata: dict with any features your survival model expects (one row)\n",
        "    returns: predicted median resolution time and probability of breach by t days (e.g., 7)\n",
        "    \"\"\"\n",
        "    if cph is None:\n",
        "        raise RuntimeError(\"Survival model not loaded\")\n",
        "    # You must build a single-row DataFrame with same feature columns used for training.\n",
        "    # Example below assumes cph was trained on many dummy/one-hot columns; adjust as necessary.\n",
        "    df = pd.DataFrame([metadata])\n",
        "    # predict median:\n",
        "    try:\n",
        "        median = cph.predict_median(df)[0]\n",
        "    except Exception as e:\n",
        "        median = None\n",
        "    # predict survival function and compute P(T>t) or P(breach by t)\n",
        "    t_query = metadata.get(\"t_query\", 7)\n",
        "    try:\n",
        "        surv = cph.predict_survival_function(df)\n",
        "        # surv is a DataFrame (index = timeline) ; pick/interpolate p(T > t_query)\n",
        "        surv_vals = surv.iloc[:, 0]\n",
        "        if t_query in surv_vals.index:\n",
        "            p_not_breach = float(surv_vals.loc[t_query])\n",
        "        else:\n",
        "            # linear interpolate\n",
        "            p_not_breach = float(np.interp(t_query, surv_vals.index.values, surv_vals.values))\n",
        "        p_breach = 1.0 - p_not_breach\n",
        "    except Exception as e:\n",
        "        p_breach = None\n",
        "    return {\"predicted_median_days\": median, \"breach_prob_at_t\": p_breach}\n"
      ],
      "metadata": {
        "id": "KZm1c9_3Pj4S"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 6\n",
        "app = FastAPI(title=\"SecureResult Colab API\")\n",
        "\n",
        "class PredictRequest(BaseModel):\n",
        "    text: str\n",
        "    course_code: Optional[str] = None\n",
        "    semester: Optional[str] = None\n",
        "    student_program: Optional[str] = None\n",
        "    faculty_department: Optional[str] = None\n",
        "    t_query: Optional[int] = 7  # days threshold for SLA\n",
        "\n",
        "class PredictResponse(BaseModel):\n",
        "    category: str\n",
        "    confidence: float\n",
        "    top_keywords: list\n",
        "    similar: list\n",
        "    sla: dict"
      ],
      "metadata": {
        "id": "Wd4v8vheP24Y"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.get(\"/health\")\n",
        "def health():\n",
        "    return {\"status\": \"ok\", \"models_loaded\": {\"classifier\": bool(classifier), \"sbert\": bool(sbert), \"sla\": bool(cph)}}"
      ],
      "metadata": {
        "id": "LkWLzO59P4nW"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.post(\"/predict\", response_model=dict)\n",
        "def predict(req: PredictRequest):\n",
        "    cat = predict_category(req.text)\n",
        "    similar = find_similar_complaint(req.text, top_k=1)\n",
        "    # build metadata for SLA: adapt fields to what your cph expects (one-hot names etc)\n",
        "    metadata = {\n",
        "        \"t_query\": req.t_query,\n",
        "        # include any categorical encodings required by your trained cph.\n",
        "        # For example, if you used Faculty Department dummy columns, you must set those exactly.\n",
        "        # Simplest option: include only features used in your notebook when you trained the cph.\n",
        "        \"Complaint Type\": cat[\"prediction\"],\n",
        "        \"Faculty Department\": req.faculty_department or \"\",\n",
        "        # Add others as required...\n",
        "    }\n",
        "    sla_out = {}\n",
        "    try:\n",
        "        sla_out = predict_sla_risk(metadata)\n",
        "    except Exception as e:\n",
        "        sla_out = {\"error\": str(e)}\n",
        "    out = {\n",
        "        \"category\": cat[\"prediction\"],\n",
        "        \"confidence\": cat[\"confidence\"],\n",
        "        \"top_keywords\": cat[\"top_keywords\"],\n",
        "        \"similar\": similar,\n",
        "        \"sla\": sla_out\n",
        "    }\n",
        "    return out"
      ],
      "metadata": {
        "id": "Wa2quvN2P7_D"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.post(\"/similar\")\n",
        "def similar(req: PredictRequest):\n",
        "    return {\"similar\": find_similar_complaint(req.text, top_k=3)}"
      ],
      "metadata": {
        "id": "uhqh2BlmP-Eg"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.post(\"/sla\")\n",
        "def sla(req: PredictRequest):\n",
        "    metadata = {\n",
        "        \"t_query\": req.t_query,\n",
        "        \"Complaint Type\": req.text  # placeholder - adapt\n",
        "    }\n",
        "    try:\n",
        "        return predict_sla_risk(metadata)\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n"
      ],
      "metadata": {
        "id": "309PCMYxPuAQ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install pyngrok if not installed\n",
        "!pip install -q pyngrok\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# set token securely (replace with your token)\n",
        "NGROK_TOKEN = \"\"   # <- paste token here (do NOT push to repo)\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "# now connect\n",
        "public_url = ngrok.connect(8000)   # or the port uvicorn will expose\n",
        "print(\"Public URL:\", public_url.public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeXrKF9lSHLQ",
        "outputId": "6926570b-3dee-45e3-f92d-2b194b295f71"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://daphine-wariest-correctingly.ngrok-free.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the API with uvicorn in the notebook (non-blocking)\n",
        "import threading, time\n",
        "\n",
        "def run_uvicorn():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "t = threading.Thread(target=run_uvicorn, daemon=True)\n",
        "t.start()\n",
        "\n",
        "print(\"Server started. Health:\", public_url.public_url + \"/health\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rIPIvVSP_3l",
        "outputId": "3999d097-3f3c-4877-802c-15aa3abcc096"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server started. Health: https://daphine-wariest-correctingly.ngrok-free.dev/health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/uvicorn/server.py:67: RuntimeWarning: coroutine 'Server.serve' was never awaited\n",
            "  return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "Exception in thread Thread-9 (run_uvicorn):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n"
          ]
        }
      ]
    }
  ]
}